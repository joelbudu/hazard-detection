{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperas proglog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import proglog\n",
    "proglog.notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import proglog\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import time\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.utils import multi_gpu_model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [10,50,100]),\n",
      "        'Dense_1': hp.choice('Dense_1', [10,50,100]),\n",
      "        'Dense_2': hp.choice('Dense_2', [10,50,100]),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [1024, 2048]),\n",
      "    }\n",
      "\n",
      ">>> Functions\n",
      "  1: def norm(data):\n",
      "  2:     height= 375\n",
      "  3:     width = 1242\n",
      "  4:     \n",
      "  5:     data.loc[:,'xmin'] = data['xmin'] / width \n",
      "  6:     data.loc[:,'xmax'] = data['xmax'] / width\n",
      "  7:     data.loc[:,'ymax'],data.loc[:,'ymin']  = (height - data['ymin']) / height , (height - data['ymax']) / height\n",
      "  8:     \n",
      "  9:     return data\n",
      " 10: \n",
      " 11: \n",
      ">>> Data\n",
      "  1: \n",
      "  2: # ----------- import data and scaling ----------- #\n",
      "  3: df_train = pd.read_csv('data/train.csv')\n",
      "  4: df_test = pd.read_csv('data/test.csv')\n",
      "  5: \n",
      "  6: X_train = df_train[['ymin','xmin','ymax', 'xmax']]\n",
      "  7: y_train = df_train[['xloc','zloc']].values\n",
      "  8: \n",
      "  9: X_test = df_test[['ymin','xmin','ymax', 'xmax']]\n",
      " 10: y_test = df_test[['xloc','zloc']].values\n",
      " 11: \n",
      " 12: X_train = norm(X_train).values\n",
      " 13: X_test = norm(X_test).values\n",
      " 14: \n",
      " 15: \n",
      " 16: \n",
      " 17: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     # ----------- define model ----------- #\n",
      "   4:     model = Sequential()\n",
      "   5: \n",
      "   6:     model.add(Dense(space['Dense'], input_shape=(4,)))\n",
      "   7: \n",
      "   8:     model.add(Dense(space['Dense_1'], activation='relu'))\n",
      "   9:     model.add(Dense(space['Dense_2'], activation='relu'))\n",
      "  10:    \n",
      "  11: \n",
      "  12:     model.add(Dense(2))\n",
      "  13: \n",
      "  14: #     model = multi_gpu_model(model, gpus=2)\n",
      "  15:     model.compile(loss='mean_squared_error', metrics=['mae'],\n",
      "  16:                   optimizer=space['optimizer'])\n",
      "  17: \n",
      "  18:     # ----------- define callbacks ----------- #\n",
      "  19:     earlyStopping = EarlyStopping(monitor='loss', patience=10, verbose=0, mode='min')\n",
      "  20:     reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=7,\n",
      "  21: \t\t\t\t\t\t\t\t       verbose=1, epsilon=1e-5, mode='min')\n",
      "  22: #     tensorboard = TensorBoard(log_dir=\"logs/model@{}\".format(int(time.time())))\n",
      "  23: \n",
      "  24:     # ----------- start training ----------- #\n",
      "  25:     model.fit(X_train, y_train,\n",
      "  26:               batch_size=space['batch_size'],\n",
      "  27:               epochs=2000,\n",
      "  28: #               callbacks=[tensorboard],\n",
      "  29:               verbose=0,\n",
      "  30:               validation_split=0.2)\n",
      "  31: \n",
      "  32:     # ----------- evaluate model ----------- #\n",
      "  33:     score, acc = model.evaluate(X_test, y_test, verbose=1)\n",
      "  34:     print('Test accuracy:', score)\n",
      "  35: \n",
      "  36:     # ----------- save model and weights ----------- #\n",
      "  37: \n",
      "  38:     return {'loss': score, 'status': STATUS_OK, 'model': model}\n",
      "  39: \n",
      "  0%|          | 0/3 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/128 [..............................]             \n",
      " - ETA: 0s - loss: 204.5824 - mae: 10.4179           \n",
      "                                                    \n",
      " 34/128 [======>.......................]             \n",
      " - ETA: 0s - loss: 186.3542 - mae: 10.0413           \n",
      "                                                    \n",
      " 64/128 [==============>...............]             \n",
      " - ETA: 0s - loss: 182.2450 - mae: 9.9436            \n",
      "                                                     \n",
      " 95/128 [=====================>........]             \n",
      " - ETA: 0s - loss: 180.2037 - mae: 9.8998            \n",
      "                                                     \n",
      "126/128 [============================>.]             \n",
      " - ETA: 0s - loss: 179.7433 - mae: 9.8765            \n",
      "                                                     \n",
      "128/128 [==============================]             \n",
      " - 0s 2ms/step - loss: 179.7898 - mae: 9.8735        \n",
      "\n",
      "Test accuracy:                                       \n",
      "179.7898406982422                                    \n",
      " 33%|███▎      | 1/3 [01:21<02:43, 81.75s/trial, best loss: 179.7898406982422]WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  1/128 [..............................]                                      \n",
      " - ETA: 0s - loss: 11.2265 - mae: 2.0254                                      \n",
      "                                                                             \n",
      " 33/128 [======>.......................]                                      \n",
      " - ETA: 0s - loss: 12.0321 - mae: 1.8845                                      \n",
      "                                                                             \n",
      " 64/128 [==============>...............]                                      \n",
      " - ETA: 0s - loss: 12.0417 - mae: 1.8737                                      \n",
      "                                                                             \n",
      " 96/128 [=====================>........]                                      \n",
      " - ETA: 0s - loss: 12.2690 - mae: 1.8752                                      \n",
      "                                                                             \n",
      "128/128 [==============================]                                      \n",
      " - ETA: 0s - loss: 12.1773 - mae: 1.8586                                      \n",
      "                                                                             \n",
      "128/128 [==============================]                                      \n",
      " - 0s 2ms/step - loss: 12.1773 - mae: 1.8586                                  \n",
      "\n",
      "Test accuracy:                                                                \n",
      "12.177322387695312                                                            \n",
      " 67%|██████▋   | 2/3 [03:54<01:43, 103.12s/trial, best loss: 12.177322387695312]WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  1/128 [..............................]                                        \n",
      " - ETA: 0s - loss: 15.1695 - mae: 1.7870                                        \n",
      "                                                                               \n",
      " 34/128 [======>.......................]                                        \n",
      " - ETA: 0s - loss: 10.2271 - mae: 1.6424                                        \n",
      "                                                                               \n",
      " 65/128 [==============>...............]                                        \n",
      " - ETA: 0s - loss: 9.7181 - mae: 1.6138                                         \n",
      "                                                                                \n",
      " 97/128 [=====================>........]                                        \n",
      " - ETA: 0s - loss: 10.0459 - mae: 1.6174                                        \n",
      "                                                                               \n",
      "128/128 [==============================]                                        \n",
      " - ETA: 0s - loss: 10.1220 - mae: 1.6068                                        \n",
      "                                                                               \n",
      "128/128 [==============================]                                        \n",
      " - 0s 2ms/step - loss: 10.1220 - mae: 1.6068                                    \n",
      "\n",
      "Test accuracy:                                                                  \n",
      "10.122035026550293                                                              \n",
      "100%|██████████| 3/3 [06:07<00:00, 122.51s/trial, best loss: 10.122035026550293]\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 10.1220 - mae: 1.6068\n",
      "Evaluation of best performing model: [10.122035026550293, 1.6068387031555176]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Dense': 50, 'Dense_1': 10, 'Dense_2': 100, 'batch_size': 1024, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice\n",
    "\n",
    "def norm(data):\n",
    "    height= 375\n",
    "    width = 1242\n",
    "    \n",
    "    data.loc[:,'xmin'] = data['xmin'] / width \n",
    "    data.loc[:,'xmax'] = data['xmax'] / width\n",
    "    data.loc[:,'ymax'],data.loc[:,'ymin']  = (height - data['ymin']) / height , (height - data['ymax']) / height\n",
    "    \n",
    "    return data\n",
    "\n",
    "def data():\n",
    "    # ----------- import data and scaling ----------- #\n",
    "    df_train = pd.read_csv('data/train.csv')\n",
    "    df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "    X_train = df_train[['ymin','xmin','ymax', 'xmax']]\n",
    "    y_train = df_train[['xloc','zloc']].values\n",
    "\n",
    "    X_test = df_test[['ymin','xmin','ymax', 'xmax']]\n",
    "    y_test = df_test[['xloc','zloc']].values\n",
    "\n",
    "    X_train = norm(X_train).values\n",
    "    X_test = norm(X_test).values\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def create_model(X_train, y_train, X_test, y_test):\n",
    "    # ----------- define model ----------- #\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense({{choice([10,50,100])}}, input_shape=(4,)))\n",
    "\n",
    "    model.add(Dense({{choice([10,50,100])}}, activation='relu'))\n",
    "    model.add(Dense({{choice([10,50,100])}}, activation='relu'))\n",
    "   \n",
    "\n",
    "    model.add(Dense(2))\n",
    "\n",
    "#     model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(loss='mean_squared_error', metrics=['mae'],\n",
    "                  optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
    "\n",
    "    # ----------- define callbacks ----------- #\n",
    "    earlyStopping = EarlyStopping(monitor='loss', patience=10, verbose=0, mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=7,\n",
    "\t\t\t\t\t\t\t\t       verbose=1, epsilon=1e-5, mode='min')\n",
    "#     tensorboard = TensorBoard(log_dir=\"logs/model@{}\".format(int(time.time())))\n",
    "\n",
    "    # ----------- start training ----------- #\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size={{choice([1024, 2048])}},\n",
    "              epochs=2000,\n",
    "#               callbacks=[tensorboard],\n",
    "              verbose=0,\n",
    "              validation_split=0.2)\n",
    "\n",
    "    # ----------- evaluate model ----------- #\n",
    "    score, acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print('Test accuracy:', score)\n",
    "\n",
    "    # ----------- save model and weights ----------- #\n",
    "\n",
    "    return {'loss': score, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=3,\n",
    "                                      trials=trials,\n",
    "                                      eval_space=True,\n",
    "                                      functions=[norm],\n",
    "                                     notebook_name='hyperas')\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = data()\n",
    "print(\"Evaluation of best performing model:\", best_model.evaluate(X_test, Y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dense': 50, 'Dense_1': 10, 'Dense_2': 100, 'batch_size': 1024, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(best_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
