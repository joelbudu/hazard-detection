{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfewpZcfzLgR"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-datasets\n",
    "!pip install -U tfds-nightly\n",
    "# !pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7S9DAboIJ3wU"
   },
   "outputs": [],
   "source": [
    "# !pip install -U --pre tensorflow==\"2.1\"\n",
    "!pip install tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqhBGn3TKo0b"
   },
   "outputs": [],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxz-dGgBgZHS"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOsfU9Xv3Mps"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "461lqB2veb-1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd models/research\n",
    "pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LPTyzcngy4t"
   },
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHtRKeWLib4y"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zaCb1I0r4IFF"
   },
   "outputs": [],
   "source": [
    "# ds = tfds.load('kitti', split='train',data_dir='/content/tensorflow_datasets', shuffle_files=True)\n",
    "# assert isinstance(ds, tf.data.Dataset)\n",
    "# print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrASjKhbg8DB"
   },
   "outputs": [],
   "source": [
    "# !gcloud auth login application-default\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxFBTsrlg8DF"
   },
   "outputs": [],
   "source": [
    "!gcloud config set account application-default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZWJe4bUg8DP"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7Lbg5cjg8DK"
   },
   "outputs": [],
   "source": [
    "# !gcloud auth login dissertation-0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pm0HljBV5PCg"
   },
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'kitti',\n",
    "    split=['train', 'test'],\n",
    "#     shuffle_files=True,\n",
    "    # as_supervised=True,\n",
    "#     try_gcs=True,\n",
    "    with_info=True,\n",
    "    download=False,\n",
    "#     data_dir='./tensorflow_datasets'\n",
    "    data_dir=\"gs://kitti-dataset-1\"\n",
    ")\n",
    "\n",
    "# ds = tfds.load('kitti', split='train',data_dir='/content/tensorflow_datasets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z23bQEmKZY3D"
   },
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "  model_file = model_name + '.tar.gz'\n",
    "  model_dir = tf.keras.utils.get_file(\n",
    "    fname=model_name, \n",
    "    origin=base_url + model_file,\n",
    "    untar=True)\n",
    "\n",
    "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "\n",
    "  model = tf.saved_model.load(str(model_dir))\n",
    "  model = model.signatures['serving_default']\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7porMrE1YnMq"
   },
   "outputs": [],
   "source": [
    "# model_name = 'faster_rcnn_resnet101_kitti_2018_01_28'\n",
    "model_name = 'faster_rcnn_inception_v2_coco_2018_01_28'\n",
    "# model_name = 'faster_rcnn_nas_lowproposals_coco_2018_01_28'\n",
    "detection_model = load_model(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7AC_EM6dja5"
   },
   "outputs": [],
   "source": [
    "# List of the strings that is used to add correct label for each box.\n",
    "\n",
    "# PATH_TO_LABELS = 'models/research/object_detection/data/kitti_label_map.pbtxt'\n",
    "PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5m2rdzKVpAeE"
   },
   "outputs": [],
   "source": [
    "# ds_train =ds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2zFuyj6rChP"
   },
   "outputs": [],
   "source": [
    "def normalize_img(object):\n",
    "  print(object['objects'])\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(object['image'], tf.float32) / 255., object['objects']['bbox']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZvLqBFuq5h3"
   },
   "outputs": [],
   "source": [
    "# ds_train = ds_train.map(\n",
    "#     normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "# ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "# ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vh6bGDVdOt7U"
   },
   "outputs": [],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCEmzEc_rGdN"
   },
   "outputs": [],
   "source": [
    "# ds_test = ds_test.map(\n",
    "#     normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GOyGpImZOe5-"
   },
   "outputs": [],
   "source": [
    "print(detection_model.inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hRQW2QSmd_vf"
   },
   "outputs": [],
   "source": [
    "detection_model.output_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMI1eV4-eCY2"
   },
   "outputs": [],
   "source": [
    "detection_model.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z56oS5LSg8D_"
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "  image = np.asarray(image)\n",
    "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "  input_tensor = tf.convert_to_tensor(image)\n",
    "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "  input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "  # Run inference\n",
    "  output_dict = model(input_tensor)\n",
    "\n",
    "  # All outputs are batches tensors.\n",
    "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "  # We're only interested in the first num_detections.\n",
    "  num_detections = int(output_dict.pop('num_detections'))\n",
    "  output_dict = {key:value[0, :num_detections].numpy() \n",
    "                 for key,value in output_dict.items()}\n",
    "  output_dict['num_detections'] = num_detections\n",
    "\n",
    "  # detection_classes should be ints.\n",
    "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "   \n",
    "  # Handle models with masks:\n",
    "  if 'detection_masks' in output_dict:\n",
    "    # Reframe the the bbox mask to the image size.\n",
    "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "               image.shape[0], image.shape[1])      \n",
    "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                       tf.uint8)\n",
    "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "    \n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "  \n",
    "\n",
    "    image_np = np.copy(image) #TODO: make more efficent \n",
    "    \n",
    "    output_dict = run_inference_for_single_image(detection_model, image_np)\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=1)\n",
    "    return image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZ32ZyN7g8EA"
   },
   "outputs": [],
   "source": [
    "def show_inference(model, tensor):\n",
    "  \n",
    "  \n",
    "    image_np = np.array(tensor)\n",
    "    image =process_image(image_np)\n",
    "    display(Image.fromarray(image))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ffJh1zAkg8EC"
   },
   "outputs": [],
   "source": [
    "# for example in ds_test.take(3):  # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
    "#     print(list(example.keys()))\n",
    "#     image = example[\"image\"]\n",
    "#     objects = example[\"objects\"]\n",
    "  \n",
    "# #     print(objects['location'])\n",
    "#     show_inference(detection_model, image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D4g2fSSqwHx-"
   },
   "outputs": [],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation Steps\n",
    "\n",
    "\n",
    "from object_detection import eval_util\n",
    "from object_detection.core import standard_fields as fields\n",
    "from object_detection.metrics import coco_evaluation\n",
    "from object_detection.protos import eval_pb2\n",
    "from object_detection.utils import test_case\n",
    "from object_detection.utils import tf_version\n",
    "\n",
    "def test_get_eval_metric_ops_for_coco_detections(eval_dict, batch_size=1,\n",
    "                                               max_gt_boxes=None,\n",
    "                                               scale_to_absolute=False):\n",
    "    eval_config = eval_pb2.EvalConfig()\n",
    "    eval_config.metrics_set.extend(['pascal_voc_detection_metrics'])\n",
    "    categories = list(category_index.values())\n",
    "\n",
    "    metric_ops = eval_util.get_eval_metric_ops_for_evaluators(\n",
    "        eval_config, categories, eval_dict)\n",
    "    _, update_op = metric_ops['DetectionBoxes_Precision/mAP']\n",
    "\n",
    "    with self.test_session() as sess:\n",
    "        metrics = {}\n",
    "        for key, (value_op, _) in six.iteritems(metric_ops):\n",
    "            metrics[key] = value_op\n",
    "        sess.run(update_op)\n",
    "        metrics = sess.run(metrics)\n",
    "        print(metrics)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Complete Evaluation steps\n",
    "\n",
    "input_data_fields = fields.InputDataFields\n",
    "detection_fields = fields.DetectionResultFields\n",
    "\n",
    "for example in ds_test.take(1):  # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
    "    print(list(example.keys()))\n",
    "    image = example[\"image\"]\n",
    "    objects = example[\"objects\"]\n",
    "  \n",
    "#     print( objects)\n",
    "    print(objects['location'])\n",
    "#     show_inference(detection_model, image)\n",
    "    image_np = np.array(image)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(detection_model, image_np)\n",
    "    \n",
    "#       return eval_util.result_dict_for_single_example(\n",
    "#           image, key, detections, groundtruth,\n",
    "#           scale_to_absolute=scale_to_absolute)\n",
    "\n",
    "\n",
    "#     batch_size = 100\n",
    "#     key = tf.constant([str(i) for i in range(batch_size)])\n",
    "\n",
    "    key = tf.constant('image1')\n",
    "    \n",
    "    groundtruth_boxes = objects['bbox']\n",
    "    groundtruth_classes = objects['type']\n",
    "    groundtruth = {\n",
    "        input_data_fields.groundtruth_boxes: groundtruth_boxes,\n",
    "        input_data_fields.groundtruth_classes: groundtruth_classes,\n",
    "      \n",
    "    }\n",
    "    \n",
    "#     num_detections = tf.convert_to_tensor([len(output_dict['detection_classes'])])\n",
    "    batch_size = 375\n",
    "    num_detection = tf.ones([batch_size])\n",
    "    detections = {\n",
    "        detection_fields.detection_boxes:  output_dict['detection_boxes'],\n",
    "        detection_fields.detection_scores: output_dict['detection_scores'],\n",
    "        detection_fields.detection_classes: output_dict['detection_classes'],\n",
    "        detection_fields.num_detections: num_detections\n",
    "       \n",
    "    }\n",
    "    result_dict = eval_util.result_dict_for_single_example(image, key,detections, groundtruth)\n",
    "#     test_get_eval_metric_ops_for_coco_detections(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110M accident_compilation.mp4\n"
     ]
    }
   ],
   "source": [
    "!ls -sh accident_compilation.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output1.mp4.\n",
      "Moviepy - Writing video output1.mp4\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e30c25f37a4592b53a1ee137c459f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='t', max=24741.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import proglog\n",
    "proglog.notebook()\n",
    "\n",
    "write_output = 'output1.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first n seconds\n",
    "# clip1 = VideoFileClip(\"test.mp4\").subclip(0,1)\n",
    "\n",
    "# clip1 = VideoFileClip(\"test.mp4\")\n",
    "\n",
    "clip1 = VideoFileClip(\"accident_compilation.mp4\")\n",
    "\n",
    "\n",
    "white_clip = clip1.fl_image(process_image) \n",
    "\n",
    "white_clip.write_videofile(write_output, audio=False, verbose=False)\n",
    "\n",
    "clip1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "kernel4b7879e069 (3).ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
