{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfewpZcfzLgR"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-datasets\n",
    "!pip install -U tfds-nightly --user\n",
    "# !pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.__version__)\n",
    "# !pip install tensorflow==2.* --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7S9DAboIJ3wU"
   },
   "outputs": [],
   "source": [
    "# !pip install -U --pre tensorflow==\"2.1\"\n",
    "!pip install tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqhBGn3TKo0b"
   },
   "outputs": [],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxz-dGgBgZHS"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.1\n",
    "# !pip install six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOsfU9Xv3Mps"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v1 as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "461lqB2veb-1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd models/research\n",
    "pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LPTyzcngy4t"
   },
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHtRKeWLib4y"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zaCb1I0r4IFF"
   },
   "outputs": [],
   "source": [
    "# ds = tfds.load('kitti', split='train',data_dir='/content/tensorflow_datasets', shuffle_files=True)\n",
    "# assert isinstance(ds, tf.data.Dataset)\n",
    "# print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrASjKhbg8DB"
   },
   "outputs": [],
   "source": [
    "# !gcloud auth login application-default\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxFBTsrlg8DF"
   },
   "outputs": [],
   "source": [
    "!gcloud config set account application-default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZWJe4bUg8DP"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7Lbg5cjg8DK"
   },
   "outputs": [],
   "source": [
    "# !gcloud auth login dissertation-0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pm0HljBV5PCg"
   },
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'kitti',\n",
    "    split=['train', 'test'],\n",
    "#     shuffle_files=True,\n",
    "    # as_supervised=True,\n",
    "#     try_gcs=True,\n",
    "    with_info=True,\n",
    "    download=False,\n",
    "#     data_dir='./tensorflow_datasets'\n",
    "    data_dir=\"gs://kitti-dataset-1\"\n",
    ")\n",
    "\n",
    "# ds = tfds.load('kitti', split='train',data_dir='/content/tensorflow_datasets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z23bQEmKZY3D"
   },
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "  model_file = model_name + '.tar.gz'\n",
    "  model_dir = tf.keras.utils.get_file(\n",
    "    fname=model_name, \n",
    "    origin=base_url + model_file,\n",
    "    untar=True)\n",
    "\n",
    "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "\n",
    "  model = tf.saved_model.load(str(model_dir))\n",
    "  model = model.signatures['serving_default']\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7porMrE1YnMq"
   },
   "outputs": [],
   "source": [
    "\n",
    "# model_name = 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03'\n",
    "# model_name = 'ssd_inception_v2_coco_2018_01_28'\n",
    "model_name = 'faster_rcnn_resnet50_lowproposals_coco_2018_01_28'\n",
    "# model_name = 'faster_rcnn_resnet101_kitti_2018_01_28'\n",
    "# model_name = 'faster_rcnn_inception_v2_coco_2018_01_28'\n",
    "# model_name = 'faster_rcnn_nas_lowproposals_coco_2018_01_28'\n",
    "detection_model = load_model(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7AC_EM6dja5"
   },
   "outputs": [],
   "source": [
    "# List of the strings that is used to add correct label for each box.\n",
    "\n",
    "# PATH_TO_LABELS = 'models/research/object_detection/data/kitti_label_map.pbtxt'\n",
    "PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5m2rdzKVpAeE"
   },
   "outputs": [],
   "source": [
    "# ds_train =ds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2zFuyj6rChP"
   },
   "outputs": [],
   "source": [
    "def normalize_img(object):\n",
    "  print(object['objects'])\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(object['image'], tf.float32) / 255., object['objects']['bbox']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZvLqBFuq5h3"
   },
   "outputs": [],
   "source": [
    "# ds_train = ds_train.map(\n",
    "#     normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "# ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "# ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vh6bGDVdOt7U"
   },
   "outputs": [],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCEmzEc_rGdN"
   },
   "outputs": [],
   "source": [
    "# ds_test = ds_test.map(\n",
    "#     normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GOyGpImZOe5-"
   },
   "outputs": [],
   "source": [
    "print(detection_model.inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hRQW2QSmd_vf"
   },
   "outputs": [],
   "source": [
    "detection_model.output_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMI1eV4-eCY2"
   },
   "outputs": [],
   "source": [
    "detection_model.output_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output format\n",
    "\n",
    "\n",
    "- Output classes are always integers in the range 0, num_classes). Any mapping of these integers to semantic labels is to be handled outside of this class. We never explicitly emit a “background class” --- thus 0 is the first non-background class and any logic of predicting and removing implicit background classes must be handled internally by the implementation.\n",
    "\n",
    "\n",
    "- Detected boxes are to be interpreted as being in (y_min, x_min, y_max, x_max) format and normalized relative to the image window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z56oS5LSg8D_"
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "  image = np.asarray(image)\n",
    "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "  input_tensor = tf.convert_to_tensor(image)\n",
    "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "  input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "  # Run inference\n",
    "  output_dict = model(input_tensor)\n",
    "\n",
    "  # All outputs are batches tensors.\n",
    "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "  # We're only interested in the first num_detections.\n",
    "  num_detections = int(output_dict.pop('num_detections'))\n",
    "  output_dict = {key:value[0, :num_detections].numpy() \n",
    "                 for key,value in output_dict.items()}\n",
    "  output_dict['num_detections'] = num_detections\n",
    "\n",
    "  # detection_classes should be ints.\n",
    "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "   \n",
    "  # Handle models with masks:\n",
    "  if 'detection_masks' in output_dict:\n",
    "    # Reframe the the bbox mask to the image size.\n",
    "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "               image.shape[0], image.shape[1])      \n",
    "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                       tf.uint8)\n",
    "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "    \n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(data):\n",
    "    height= 375\n",
    "    width = 1242\n",
    "    \n",
    "    data['xmin'] = data['xmin'] / width \n",
    "    data['xmax'] = data['xmax'] / width\n",
    "    data['ymin'] = (height - data['ymin']) / height\n",
    "    data['ymax'] = (height - data['ymax']) / height\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "\n",
    "\n",
    "# ----------- import data and scaling ----------- #\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "X_train = df_train[['xmin', 'xmax', 'ymin' ,'ymax']]\n",
    "y_train = df_train[['xloc', 'yloc','zloc']].values\n",
    "\n",
    "X_test = df_test[['xmin', 'xmax', 'ymin','ymax']].values\n",
    "y_test = df_test[['xloc', 'yloc','zloc']].values\n",
    "\n",
    "#  ymin=(height - bbox.bottom) / height,\n",
    "#       ymax=(height - bbox.top) / height,\n",
    "#       xmin=bbox.left / width,\n",
    "#       xmax=bbox.right / width,\n",
    "# 375 ,1242\n",
    "# standardized data\n",
    "# xScalar = StandardScaler()\n",
    "# yScalar = StandardScaler()\n",
    "# X_train = xScalar.fit_transform(X_train)\n",
    "# y_train = yScalar.fit_transform(y_train)\n",
    "\n",
    "X_train = norm(X_train).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df_train[['xmin', 'xmax', 'ymin' ,'ymax']].values\n",
    "\n",
    "print(X_train[:10])\n",
    "\n",
    "# X_train = norm(X_train)\n",
    "# X_train[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING MODE\n",
    "\n",
    "\n",
    "# ----------- create model ----------- #\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(6, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(150, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(150, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(100, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal'))\n",
    "\n",
    "\n",
    "# opt = tf.keras.optimizers.Adam(\n",
    "#     learning_rate=0.001\n",
    "# )\n",
    "# model = multi_gpu_model(model, gpus=2)\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "# ----------- define callbacks ----------- #\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7,\n",
    "                verbose=1, min_delta=1e-4, mode='min')\n",
    "modelname = \"model@{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(modelname))\n",
    "\n",
    "# ----------- start training ----------- #\n",
    "history = model.fit(X_train, y_train,\n",
    "            validation_split=0.1, epochs=10000, batch_size=8000,verbose=0, callbacks=[tensorboard, TqdmCallback(verbose=1)])\n",
    "\n",
    "\n",
    "# ----------- save model and weights ----------- #\n",
    "model_json = model.to_json()\n",
    "with open(\"generated_files/{}.json\".format(modelname), \"w\") as json_file:\n",
    "   json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"generated_files/{}.h5\".format(modelname))\n",
    "print(\"Saved model to disk\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot({'Basic': history}, metric = \"loss\")\n",
    "plt.ylim([0, 10])\n",
    "plt.ylabel('MAE [MPG]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCE MODE\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "X_test = df_test[['xmin', 'xmax', 'ymin','ymax']]\n",
    "y_test = df_test[['xloc' ,'yloc','zloc']].values\n",
    "\n",
    "# standardized data\n",
    "# scalar = MinMaxScaler()\n",
    "# X_test = scalar.fit_transform(X_test)\n",
    "# y_test = yScalar.fit_transform(y_test)\n",
    "    \n",
    "X_test = norm(X_test).values\n",
    "print(X_test[:10])\n",
    "\n",
    "# MODEL = \"model@1595813111\"\n",
    "# WEIGHTS = \"model@1595813111\"\n",
    "\n",
    "MODEL = modelname\n",
    "WEIGHTS = modelname\n",
    "\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('generated_files/{}.json'.format(MODEL), 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json( loaded_model_json )\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"generated_files/{}.h5\".format(WEIGHTS))\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# loaded_model = model\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "\n",
    "# scale up predictions to original values\n",
    "# y_pred_transformed = yScalar.inverse_transform(y_pred)\n",
    "# y_test_transformed = yScalar.inverse_transform(y_test)\n",
    "\n",
    "# y_pred_transformed = y_pred\n",
    "# save predictions\n",
    "df_result = df_test\n",
    "df_result['zloc_pred'] = -100000\n",
    "df_result['xloc_pred'] = -100000\n",
    "\n",
    "\n",
    "for idx, row in df_result.iterrows():\n",
    "    df_result.at[idx, 'zloc_pred'] = y_pred[idx][2]\n",
    "    df_result.at[idx, 'xloc_pred'] = y_pred[idx][0]\n",
    "\n",
    "df_result.to_csv('data/predictions2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_locnet( bboxes):\n",
    "  \n",
    "    if len(bboxes)==0 or len(bboxes)==1 and not any(bboxes[0]):\n",
    "        return []\n",
    "#     bboxes = xScalar.transform(bboxes)\n",
    "    y_pred = loaded_model.predict(bboxes)\n",
    "    # scale up predictions to original values\n",
    "#     y_pred_transformed = yScalar.inverse_transform(y_pred)\n",
    "\n",
    "    return y_pred\n",
    "#     return y_pred_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_kitti(classes):\n",
    "    \n",
    "    hash = { 3:1 , 8:3, 1:4, 7:7 }\n",
    "    return [ hash.get(classes[i], 8) for i in range(len(classes)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_detections( output_dict):\n",
    "    \n",
    "    output_dict['detection_classes'] = transform_to_kitti(output_dict['detection_classes'])\n",
    "    \n",
    "#     print(output_dict  )\n",
    "    misc_ids = (8,9)\n",
    "    \n",
    "    scores = output_dict['detection_scores']\n",
    "    classes = output_dict['detection_classes']\n",
    "    \n",
    "    size = len(classes)\n",
    "    min_threshhold = 0.5\n",
    "    output_dict['detection_boxes'] = np.array([ output_dict['detection_boxes'][i] for i in range(size) if scores[i] >= min_threshhold and classes[i] not in misc_ids  ])\n",
    "    output_dict['detection_classes'] = np.array([ output_dict['detection_classes'][i] for i in range(size) if scores[i] >= min_threshhold and classes[i] not in misc_ids  ])\n",
    "    output_dict['detection_scores'] = np.array([ output_dict['detection_scores'][i] for i in range(size) if scores[i] >= min_threshhold and classes[i] not in misc_ids  ])\n",
    "\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_up_boxes( output_dict):\n",
    "    \n",
    "    output_dict['detection_boxes'] = output_dict['detection_boxes'] * 1000\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install filterpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Sort object\n",
    "from sort import *\n",
    "mot_tracker = Sort( max_age=7, min_hits=2, iou_threshold=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_for_sort(array):\n",
    "\n",
    "     return np.array( [array[1] ,array[0], array[3], array[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_detections_for_mot(outputdict):\n",
    "    \n",
    "    detections = [ np.append( reorder_for_sort(outputdict['detection_boxes'][i]) , outputdict['detection_scores'][i])  for i in range( len(outputdict['detection_classes'])) ] \n",
    "    \n",
    "    return np.asarray(detections)  if len(detections) else np.empty((0, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_boxes( boxes):\n",
    "    \n",
    "    result = boxes.numpy()\n",
    "    for box in result:\n",
    "        box[0]=1-box[0]\n",
    "        box[2]=1-box[2]\n",
    "        box[0],box[2] = box[2], box[0]\n",
    "    return tf.convert_to_tensor(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image, groundtruth=None):\n",
    "  \n",
    "\n",
    "    image_np = np.copy(image) #TODO: make more efficent \n",
    "    \n",
    "    output_dict = run_inference_for_single_image(detection_model, image_np)\n",
    "    \n",
    "    output_dict =filter_detections( output_dict)\n",
    "\n",
    "    locations = run_locnet( output_dict['detection_boxes'])\n",
    "    \n",
    "    detections = format_detections_for_mot(output_dict)\n",
    "    \n",
    "        \n",
    "    \n",
    "#     print( 'detections', detections)\n",
    "    tracked_objects = mot_tracker.update(detections)\n",
    "    \n",
    "#     tracked_ids = [ int(obj[-1]) for obj in tracked_objects]\n",
    "#     print(\"Tracked objects: \" , tracked_objects)\n",
    "    \n",
    "#     print( \"distance_vector\")\n",
    "\n",
    "#     print( locations)\n",
    "    print(  'outdict_boxes',output_dict['detection_boxes'])\n",
    "    print(\"detections\",detections)\n",
    "#     print(tracked_objects)\n",
    "#     print(tracked_ids)\n",
    "#     print(len(detections), len(tracked_ids))\n",
    "    global tracked_ids   \n",
    "    if len(detections) == len(tracked_objects):\n",
    "#         print('n')\n",
    "        tracked_ids = [ int(obj[-1]) for obj in tracked_objects]\n",
    "    # Visualization of the results of a detection.\n",
    "    \n",
    "    tracked_ids = None #Disble tracking for now\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      cat_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=1,\n",
    "      track_ids=tracked_ids,)\n",
    "    \n",
    "\n",
    "    if groundtruth:\n",
    "        groundtruth_boxes = format_boxes(objects['bbox']).numpy()\n",
    "        groundtruth_classes = objects['type'].numpy()+1\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      groundtruth_boxes,\n",
    "      groundtruth_classes,\n",
    "        None,\n",
    "      cat_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=1)\n",
    "#     for object in tracked_objects:\n",
    "        \n",
    "#         xmin,ymin,xmax,ymax = object[:4]\n",
    "# #         print(\"obj\",object[:4])\n",
    "#         label = \"det\"+str(object[4])\n",
    "#         vis_util.draw_bounding_box_on_image_array(image_np, xmin, ymin, xmax, ymax, thickness=1, display_str_list=[label])\n",
    "    \n",
    "    return image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_locnet( [[0.41085333,0.4335749 ,0.5223467 ,0.4712963 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "# %reload_ext tensorboard\n",
    "\n",
    "\n",
    "%tensorboard --logdir logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZ32ZyN7g8EA"
   },
   "outputs": [],
   "source": [
    "def show_inference(model, tensor, groundtruth=None):\n",
    "  \n",
    "    image_np = np.array(tensor)\n",
    "    image =process_image(image_np,groundtruth)\n",
    "    display(Image.fromarray(image))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ffJh1zAkg8EC"
   },
   "outputs": [],
   "source": [
    "for example in ds_test.take(20):  # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
    "    print(list(example.keys()))\n",
    "    image = example[\"image\"]\n",
    "    objects = example[\"objects\"]\n",
    "  \n",
    "    print('bbox:' ,objects['bbox'])\n",
    "    print('location:', objects['location'])\n",
    "    print('type:', objects['type'])\n",
    "    show_inference(detection_model, image, objects)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on bbox from tfds\n",
    "\n",
    "bbox: tf.Tensor of type `tf.float32` and shape `[4,]` which contains the\n",
    "      normalized coordinates of the bounding box `[ymin, xmin, ymax, xmax]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categories = [{\n",
    "        'id': 1,\n",
    "        'name': 'car'\n",
    "    }, {\n",
    "        'id': 2,\n",
    "        'name': 'van'\n",
    "    }, {\n",
    "        'id': 3,\n",
    "        'name': 'truck'\n",
    "    }, {\n",
    "        'id': 4,\n",
    "        'name': 'pedestrian'\n",
    "    }]\n",
    "\n",
    "cat_index  = {i+1: val for i,val in enumerate(categories) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Complete Evaluation steps\n",
    "\n",
    "from object_detection import eval_util\n",
    "from object_detection.core import standard_fields as fields\n",
    "from object_detection.metrics import coco_evaluation\n",
    "from object_detection.protos import eval_pb2\n",
    "from object_detection.utils import test_case\n",
    "from object_detection.utils import tf_version\n",
    "\n",
    "input_data_fields = fields.InputDataFields\n",
    "detection_fields = fields.DetectionResultFields\n",
    "\n",
    "\n",
    "for example in ds_test.take(15):  # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
    "    image = example[\"image\"]\n",
    "    objects = example[\"objects\"]\n",
    "#     show_inference(detection_model, image)\n",
    "    image_np = np.array(image)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(detection_model, image_np)\n",
    "\n",
    "\n",
    "    output_dict = filter_detections( output_dict)\n",
    "\n",
    "    batch_size = 1\n",
    "    key=tf.constant('image1')\n",
    "    \n",
    "    groundtruth_boxes = format_boxes(objects['bbox'])\n",
    "    groundtruth_classes = objects['type']+1\n",
    "    groundtruth = {\n",
    "        input_data_fields.groundtruth_boxes: groundtruth_boxes,\n",
    "        input_data_fields.groundtruth_classes: groundtruth_classes,      \n",
    "    }\n",
    "    \n",
    "    num_detections = tf.constant([len(output_dict['detection_classes'])])\n",
    "    \n",
    "    detections = {\n",
    "        detection_fields.detection_boxes: tf.constant([output_dict['detection_boxes']]) ,\n",
    "        detection_fields.detection_scores: tf.constant([output_dict['detection_scores']]),\n",
    "        detection_fields.detection_classes: tf.constant([output_dict['detection_classes']]),\n",
    "        detection_fields.num_detections: num_detections\n",
    "       \n",
    "    }\n",
    "    \n",
    "\n",
    "    image = tf.constant([image_np])\n",
    "    \n",
    "    \n",
    "    result_dict = eval_util.result_dict_for_single_example(image, key,detections, groundtruth)\n",
    "    \n",
    "#     result_dict2 = {k: v.numpy() for k, v in result_dict.items()}\n",
    "    side_by_side_img =  vis_util.draw_side_by_side_evaluation_image(result_dict,cat_index)[0][0].numpy()\n",
    "    display(Image.fromarray(side_by_side_img))\n",
    "#     test_get_eval_metric_ops_for_coco_detections(result_dict)\n",
    "#     test_get_estimator_eval_metric_ops(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Complete Evaluation steps\n",
    "from object_detection.core import standard_fields\n",
    "from object_detection.utils import object_detection_evaluation\n",
    "\n",
    "\n",
    "categories = [{\n",
    "        'id': 1,\n",
    "        'name': 'car'\n",
    "    }, {\n",
    "        'id': 2,\n",
    "        'name': 'van'\n",
    "    }, {\n",
    "        'id': 3,\n",
    "        'name': 'truck'\n",
    "    }, {\n",
    "        'id': 4,\n",
    "        'name': 'pedestrian'\n",
    "    }]\n",
    "\n",
    "# print( categories)\n",
    "pascal_evaluator = object_detection_evaluation.PascalDetectionEvaluator(\n",
    "        categories,matching_iou_threshold=0.3)\n",
    "\n",
    "# ,evaluate_precision_recall=True\n",
    "\n",
    "for index, example in enumerate(ds_test):  \n",
    "    image = example[\"image\"]\n",
    "    objects = example[\"objects\"]\n",
    "  \n",
    "#     show_inference(detection_model, image)\n",
    "    image_np = np.array(image)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(detection_model, image_np)\n",
    "    \n",
    "\n",
    "\n",
    "    output_dict = filter_detections( output_dict)\n",
    "    \n",
    "#     output_dict = scale_up_boxes( output_dict)\n",
    "    \n",
    "    image_key = 'img'+str(index)\n",
    "    \n",
    "\n",
    "#     groundtruth_boxes = objects['bbox'].numpy()\n",
    "    groundtruth_boxes = format_boxes(objects['bbox']).numpy()\n",
    "    groundtruth_classes = objects['type'].numpy()+1\n",
    "    \n",
    "#     print( 'ground_truth_classes' ,  groundtruth_classes)\n",
    "#     print( 'ground_truth_boxes' ,  groundtruth_boxes)\n",
    "#     print( 'detection_classes' ,  output_dict['detection_classes'])\n",
    "#     print( 'detection_boxes' ,  output_dict['detection_boxes'])\n",
    "#     print( 'detection_scores' ,  output_dict['detection_scores'])\n",
    "    \n",
    "#     print( '*'*100)\n",
    "\n",
    "\n",
    "\n",
    "    pascal_evaluator.add_single_ground_truth_image_info(\n",
    "        image_key,\n",
    "        {standard_fields.InputDataFields.groundtruth_boxes: groundtruth_boxes,\n",
    "         standard_fields.InputDataFields.groundtruth_classes:\n",
    "         groundtruth_classes,\n",
    "#          standard_fields.InputDataFields.groundtruth_difficult:\n",
    "#          groundtruth_is_difficult_list2\n",
    "        })\n",
    "\n",
    "    if len(output_dict['detection_classes']):\n",
    "        pascal_evaluator.add_single_detected_image_info(\n",
    "                image_key,\n",
    "                {standard_fields.DetectionResultFields.detection_boxes: output_dict['detection_boxes'],\n",
    "                 standard_fields.DetectionResultFields.detection_scores:\n",
    "                 output_dict['detection_scores'],\n",
    "                 standard_fields.DetectionResultFields.detection_classes:\n",
    "                 output_dict['detection_classes']\n",
    "                })\n",
    "    \n",
    "\n",
    "    metrics = pascal_evaluator.evaluate()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PascalBoxes_Precision/mAP@0.3IOU': 0.3436989244461206,\n",
       " 'PascalBoxes_PerformanceByCategory/AP@0.3IOU/car': 0.7085758062772537,\n",
       " 'PascalBoxes_PerformanceByCategory/AP@0.3IOU/van': 0.0,\n",
       " 'PascalBoxes_PerformanceByCategory/AP@0.3IOU/truck': 0.043790693769775034,\n",
       " 'PascalBoxes_PerformanceByCategory/AP@0.3IOU/pedestrian': 0.6224291977374536}"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install moviepy proglog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp gs://hazard-detection-test-videos/accident_compilation.mp4 accident_compilation.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -sh accident_compilation.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import proglog\n",
    "proglog.notebook()\n",
    "\n",
    "tracked_ids=None\n",
    "\n",
    "write_output = 'output_' + model_name + '.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first n seconds\n",
    "# clip1 = VideoFileClip(\"test.mp4\").subclip(0,1)\n",
    "\n",
    "# clip1 = VideoFileClip(\"test.mp4\")\n",
    "\n",
    "clip1 = VideoFileClip(\"accident_compilation.mp4\").subclip(20,21)\n",
    "\n",
    "\n",
    "white_clip = clip1.fl_image(process_image) \n",
    "\n",
    "white_clip.write_videofile(write_output, audio=False, verbose=False)\n",
    "\n",
    "clip1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-models-official --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python models/research/object_detection/legacy/eval.py --pipeline_config_path=gs://hazard-detection-test-videos/job_dir/pipeline.config  --checkpoint_dir=gs://hazard-detection-test-videos/job_dir --eval_dir=gs://hazard-detection-test-videos/eval_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python models/research/object_detection/model_main.py --pipeline_config_path=pipeline.config  --checkpoint_dir=checkpoint_dir --model_dir=eval_dir            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp gs://hazard-detection-test-videos/tf2model/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls checkpoint_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LocNet starts\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "kernel4b7879e069 (3).ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
