{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfewpZcfzLgR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tfds-nightly\n",
      "  Downloading tfds_nightly-3.2.1.dev202007260106-py3-none-any.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 97 bytes/s a 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: dill in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (0.3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: absl-py in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (3.12.3)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=18.1.0 in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: promise in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (2.3)\n",
      "Requirement already satisfied, skipping upgrade: future in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (4.47.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (1.19.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-metadata in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (0.22.2)\n",
      "Requirement already satisfied, skipping upgrade: termcolor in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tfds-nightly) (49.1.0.post20200704)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos in /opt/conda/lib/python3.7/site-packages (from tensorflow-metadata->tfds-nightly) (1.51.0)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tfds-nightly) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tfds-nightly) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tfds-nightly) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tfds-nightly) (3.0.4)\n",
      "Installing collected packages: tfds-nightly\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/opt/conda/lib/python3.7/site-packages/tensorflow_datasets/import_test.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow-datasets\n",
    "!pip install -U tfds-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7S9DAboIJ3wU"
   },
   "outputs": [],
   "source": [
    "# !pip install -U --pre tensorflow==\"2.1\"\n",
    "# !pip install tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqhBGn3TKo0b"
   },
   "outputs": [],
   "source": [
    "# !pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxz-dGgBgZHS"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOsfU9Xv3Mps"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LPTyzcngy4t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHtRKeWLib4y"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxFBTsrlg8DF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/account].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set account application-default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "\n",
    "\n",
    "# ----------- import data and scaling ----------- #\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "X_train = df_train[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
    "y_train = df_train[['xloc', 'yloc','zloc']].values\n",
    "\n",
    "X_test = df_test[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
    "y_test = df_test[['xloc', 'yloc','zloc']].values\n",
    "\n",
    "# standardized data\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "y_train = scalar.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[676, 163, 688, 193],\n",
       "       [598, 178, 652, 218],\n",
       "       [649, 168, 664, 206],\n",
       "       ...,\n",
       "       [763, 183, 798, 204],\n",
       "       [  0, 205, 175, 368],\n",
       "       [605, 168, 621, 187]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ad3d9e8e9c48ac82626ccf66849e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# TRAINING MODE\n",
    "\n",
    "\n",
    "# ----------- create model ----------- #\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(6, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal'))\n",
    "\n",
    "# model = multi_gpu_model(model, gpus=2)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# ----------- define callbacks ----------- #\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7,\n",
    "                verbose=1, min_delta=1e-4, mode='min')\n",
    "modelname = \"model@{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(modelname))\n",
    "\n",
    "# ----------- start training ----------- #\n",
    "history = model.fit(X_train, y_train,\n",
    "            validation_split=0.1, epochs=5000, batch_size=2048,verbose=0, callbacks=[tensorboard, TqdmCallback(verbose=1)])\n",
    "\n",
    "\n",
    "# ----------- save model and weights ----------- #\n",
    "model_json = model.to_json()\n",
    "with open(\"generated_files/{}.json\".format(modelname), \"w\") as json_file:\n",
    "   json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"generated_files/{}.h5\".format(modelname))\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE MODE\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "X_test = df_test[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
    "y_test = df_test[['xloc' ,'yloc','zloc']].values\n",
    "\n",
    "# standardized data\n",
    "scalar = StandardScaler()\n",
    "X_test = scalar.fit_transform(X_test)\n",
    "y_test = scalar.fit_transform(y_test)\n",
    "    \n",
    "MODEL = \"model@1595813111\"\n",
    "WEIGHTS = \"model@1595813111\"\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('generated_files/{}.json'.format(MODEL), 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json( loaded_model_json )\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"generated_files/{}.h5\".format(WEIGHTS))\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# scale up predictions to original values\n",
    "y_pred_transformed = scalar.inverse_transform(y_pred)\n",
    "y_test_transformed = scalar.inverse_transform(y_test)\n",
    "\n",
    "# save predictions\n",
    "df_result = df_test\n",
    "df_result['zloc_pred'] = -100000\n",
    "df_result['xloc_pred'] = -100000\n",
    "\n",
    "\n",
    "for idx, row in df_result.iterrows():\n",
    "    df_result.at[idx, 'zloc_pred'] = y_pred_transformed[idx][2]\n",
    "    df_result.at[idx, 'xloc_pred'] = y_pred_transformed[idx][0]\n",
    "\n",
    "df_result.to_csv('data/predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.7497787,  0.790492 , 47.085934 ],\n",
       "       [ 1.6973345,  1.0398965, 30.420267 ],\n",
       "       [ 1.4140747,  1.020137 , 35.5445   ],\n",
       "       ...,\n",
       "       [ 8.07237  ,  1.4689236, 48.042564 ],\n",
       "       [-5.4860873,  1.0259709,  4.490592 ],\n",
       "       [ 1.4363534,  0.6259449, 65.488144 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4088/4088 - 0s - loss: 356.1009\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-105c1285cd6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing set Mean Abs Error: {:5.2f} MPG\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "source": [
    "loss, mae, mse = model.evaluate(X_test, y_test_transformed, verbose=2)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "kernel4b7879e069 (3).ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
