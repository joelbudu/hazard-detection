{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfewpZcfzLgR"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-datasets\n",
    "!pip install -U tfds-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7S9DAboIJ3wU"
   },
   "outputs": [],
   "source": [
    "# !pip install -U --pre tensorflow==\"2.1\"\n",
    "# !pip install tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqhBGn3TKo0b"
   },
   "outputs": [],
   "source": [
    "# !pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxz-dGgBgZHS"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOsfU9Xv3Mps"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LPTyzcngy4t"
   },
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHtRKeWLib4y"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxFBTsrlg8DF"
   },
   "outputs": [],
   "source": [
    "!gcloud config set account application-default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "\n",
    "# ----------- import data and scaling ----------- #\n",
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "X_train = df_train[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
    "y_train = df_train[['xloc', 'yloc','zloc']].values\n",
    "\n",
    "X_test = df_test[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
    "y_test = df_test[['xloc', 'yloc','zloc']].values\n",
    "\n",
    "# standardized data\n",
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "y_train = scalar.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING MODE\n",
    "\n",
    "# ----------- create model ----------- #\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(6, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(3, kernel_initializer='normal'))\n",
    "\n",
    "# model = multi_gpu_model(model, gpus=2)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# ----------- define callbacks ----------- #\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7,\n",
    "                verbose=1, min_delta=1e-4, mode='min')\n",
    "modelname = \"model@{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(modelname))\n",
    "\n",
    "# ----------- start training ----------- #\n",
    "history = model.fit(X_train, y_train,\n",
    "            validation_split=0.1, epochs=7000, batch_size=2048, callbacks=[tensorboard])\n",
    "\n",
    "\n",
    "# ----------- save model and weights ----------- #\n",
    "model_json = model.to_json()\n",
    "with open(\"generated_files/{}.json\".format(modelname), \"w\") as json_file:\n",
    "   json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"generated_files/{}.h5\".format(modelname))\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFERENCE MODE\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "X_test = df_test[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
    "y_test = df_test[['xloc' ,'yloc','zloc']].values\n",
    "\n",
    "# standardized data\n",
    "scalar = StandardScaler()\n",
    "X_test = scalar.fit_transform(X_test)\n",
    "y_test = scalar.fit_transform(y_test)\n",
    "    \n",
    "MODEL = \"model@1594929980\"\n",
    "WEIGHTS = \"model@1594929980\"\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('generated_files/{}.json'.format(MODEL), 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json( loaded_model_json )\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"generated_files/{}.h5\".format(WEIGHTS))\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# scale up predictions to original values\n",
    "y_pred = scalar.inverse_transform(y_pred)\n",
    "y_test = scalar.inverse_transform(y_test)\n",
    "\n",
    "# save predictions\n",
    "df_result = df_test\n",
    "df_result['zloc_pred'] = -100000\n",
    "\n",
    "for idx, row in df_result.iterrows():\n",
    "    df_result.at[idx, 'zloc_pred'] = y_pred[idx]\n",
    "\n",
    "df_result.to_csv('data/predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict( [X_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae, mse = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "kernel4b7879e069 (3).ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
