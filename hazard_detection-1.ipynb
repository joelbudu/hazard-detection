{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfewpZcfzLgR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tfds-nightly in /home/jupyter/.local/lib/python3.7/site-packages (3.2.1.dev202007270106)\n",
      "Requirement already satisfied, skipping upgrade: dill in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (0.3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: future in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: promise in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (2.3)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=18.1.0 in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (4.47.0)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-metadata in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (0.22.2)\n",
      "Requirement already satisfied, skipping upgrade: absl-py in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (1.19.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (1.12.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tfds-nightly) (3.12.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tfds-nightly) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tfds-nightly) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tfds-nightly) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->tfds-nightly) (1.25.9)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos in /opt/conda/lib/python3.7/site-packages (from tensorflow-metadata->tfds-nightly) (1.51.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tfds-nightly) (49.1.0.post20200704)\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow-datasets\n",
    "!pip install -U tfds-nightly --user\n",
    "# !pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7S9DAboIJ3wU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf_slim in /opt/conda/lib/python3.7/site-packages (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from tf_slim) (0.8.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U --pre tensorflow==\"2.1\"\n",
    "!pip install tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqhBGn3TKo0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in /opt/conda/lib/python3.7/site-packages (2.0.1)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (49.1.0.post20200704)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (3.2.2)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (0.29.20)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.19.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxz-dGgBgZHS"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOsfU9Xv3Mps"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "461lqB2veb-1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "  !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "object_detection/protos/input_reader.proto:5:1: warning: Import object_detection/protos/image_resizer.proto is unused.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jupyter/hazard-detection/models/research\n",
      "Requirement already satisfied: Pillow>=1.0 in /opt/conda/lib/python3.7/site-packages (from object-detection==0.1) (7.2.0)\n",
      "Requirement already satisfied: Matplotlib>=2.1 in /opt/conda/lib/python3.7/site-packages (from object-detection==0.1) (3.2.2)\n",
      "Requirement already satisfied: Cython>=0.28.1 in /opt/conda/lib/python3.7/site-packages (from object-detection==0.1) (0.29.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from Matplotlib>=2.1->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from Matplotlib>=2.1->object-detection==0.1) (1.19.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from Matplotlib>=2.1->object-detection==0.1) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from Matplotlib>=2.1->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from Matplotlib>=2.1->object-detection==0.1) (1.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->Matplotlib>=2.1->object-detection==0.1) (1.15.0)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py): started\n",
      "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
      "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1310302 sha256=b974f29935ddaa020f7d8e4ea821de67529ed932050cc08d8925202cc89a9bab\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-q5bfro_h/wheels/2f/69/68/d174ba7c18fe52ba5ad48455b812a18ad3d77a17bed688d8be\n",
      "Successfully built object-detection\n",
      "Installing collected packages: object-detection\n",
      "  Attempting uninstall: object-detection\n",
      "    Found existing installation: object-detection 0.1\n",
      "    Uninstalling object-detection-0.1:\n",
      "      Successfully uninstalled object-detection-0.1\n",
      "Successfully installed object-detection-0.1\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd models/research\n",
    "pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7LPTyzcngy4t"
   },
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHtRKeWLib4y"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrASjKhbg8DB"
   },
   "outputs": [],
   "source": [
    "# !gcloud auth login application-default\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxFBTsrlg8DF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/account].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set account application-default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZWJe4bUg8DP"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7Lbg5cjg8DK"
   },
   "outputs": [],
   "source": [
    "# !gcloud auth login dissertation-0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pm0HljBV5PCg"
   },
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'kitti',\n",
    "    split=['train', 'test'],\n",
    "#     shuffle_files=True,\n",
    "    # as_supervised=True,\n",
    "#     try_gcs=True,\n",
    "    with_info=True,\n",
    "    download=False,\n",
    "#     data_dir='./tensorflow_datasets'\n",
    "     data_dir=\"gs://kitti-dataset-1\"\n",
    "#          data_dir=\"gs://dissertation-0\"\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "# ds = tfds.load('kitti', split='train',data_dir='/content/tensorflow_datasets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z23bQEmKZY3D"
   },
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "  model_file = model_name + '.tar.gz'\n",
    "  model_dir = tf.keras.utils.get_file(\n",
    "    fname=model_name, \n",
    "    origin=base_url + model_file,\n",
    "    untar=True)\n",
    "\n",
    "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "\n",
    "  model = tf.saved_model.load(str(model_dir))\n",
    "  model = model.signatures['serving_default']\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7porMrE1YnMq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz\n",
      "278118400/278114232 [==============================] - 2s 0us/step\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'faster_rcnn_resnet101_kitti_2018_01_28'\n",
    "model_name = 'ssd_inception_v2_coco_2018_01_28'\n",
    "# model_name = 'faster_rcnn_inception_v2_coco_2018_01_28'\n",
    "# model_name = 'faster_rcnn_nas_lowproposals_coco_2018_01_28'\n",
    "detection_model = load_model(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7AC_EM6dja5"
   },
   "outputs": [],
   "source": [
    "# List of the strings that is used to add correct label for each box.\n",
    "\n",
    "# PATH_TO_LABELS = 'models/research/object_detection/data/kitti_label_map.pbtxt'\n",
    "PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5m2rdzKVpAeE"
   },
   "outputs": [],
   "source": [
    "# ds_train =ds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2zFuyj6rChP"
   },
   "outputs": [],
   "source": [
    "def normalize_img(object):\n",
    "  print(object['objects'])\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(object['image'], tf.float32) / 255., object['objects']['bbox']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZvLqBFuq5h3"
   },
   "outputs": [],
   "source": [
    "# ds_train = ds_train.map(\n",
    "#     normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "# ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "# ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vh6bGDVdOt7U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: {image: (None, None, 3), image/file_name: (), objects: {alpha: (None,), bbox: (None, 4), dimensions: (None, 3), location: (None, 3), occluded: (None,), rotation_y: (None,), truncated: (None,), type: (None,)}}, types: {image: tf.uint8, image/file_name: tf.string, objects: {alpha: tf.float32, bbox: tf.float32, dimensions: tf.float32, location: tf.float32, occluded: tf.int64, rotation_y: tf.float32, truncated: tf.float32, type: tf.int64}}>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCEmzEc_rGdN"
   },
   "outputs": [],
   "source": [
    "# ds_test = ds_test.map(\n",
    "#     normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GOyGpImZOe5-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'image_tensor:0' shape=(None, None, None, 3) dtype=uint8>]\n"
     ]
    }
   ],
   "source": [
    "print(detection_model.inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hRQW2QSmd_vf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detection_classes': tf.float32,\n",
       " 'detection_scores': tf.float32,\n",
       " 'num_detections': tf.float32,\n",
       " 'detection_boxes': tf.float32}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_model.output_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMI1eV4-eCY2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'detection_classes': TensorShape([None, 100]),\n",
       " 'detection_scores': TensorShape([None, 100]),\n",
       " 'num_detections': TensorShape([None]),\n",
       " 'detection_boxes': TensorShape([None, 100, 4])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_model.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z56oS5LSg8D_"
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "  image = np.asarray(image)\n",
    "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "  input_tensor = tf.convert_to_tensor(image)\n",
    "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "  input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "  # Run inference\n",
    "  output_dict = model(input_tensor)\n",
    "\n",
    "  # All outputs are batches tensors.\n",
    "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "  # We're only interested in the first num_detections.\n",
    "  num_detections = int(output_dict.pop('num_detections'))\n",
    "  output_dict = {key:value[0, :num_detections].numpy() \n",
    "                 for key,value in output_dict.items()}\n",
    "  output_dict['num_detections'] = num_detections\n",
    "\n",
    "  # detection_classes should be ints.\n",
    "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "   \n",
    "  # Handle models with masks:\n",
    "  if 'detection_masks' in output_dict:\n",
    "    # Reframe the the bbox mask to the image size.\n",
    "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
    "               image.shape[0], image.shape[1])      \n",
    "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
    "                                       tf.uint8)\n",
    "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "    \n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "  \n",
    "\n",
    "    image_np = np.copy(image) #TODO: make more efficent \n",
    "    \n",
    "    output_dict = run_inference_for_single_image(detection_model, image_np)\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np,\n",
    "      output_dict['detection_boxes'],\n",
    "      output_dict['detection_classes'],\n",
    "      output_dict['detection_scores'],\n",
    "      category_index,\n",
    "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
    "      use_normalized_coordinates=True,\n",
    "      line_thickness=1)\n",
    "    \n",
    "#     image,\n",
    "#                                ymin,\n",
    "#                                xmin,\n",
    "#                                ymax,\n",
    "#                                xmax,\n",
    "#                                color='red',\n",
    "#                                thickness=4,\n",
    "#                                display_str_list=(),\n",
    "#                                use_normalized_coordinates=True):\n",
    "\n",
    "#     print( output_dict['detection_boxes'])\n",
    "#     vis_util.draw_bounding_box_on_image_array(image_np, output_dict['detection_boxes'][])\n",
    "    \n",
    "    return image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZ32ZyN7g8EA"
   },
   "outputs": [],
   "source": [
    "def show_inference(model, tensor):\n",
    "  \n",
    "  \n",
    "    image_np = np.array(tensor)\n",
    "    image =process_image(image_np)\n",
    "    display(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ffJh1zAkg8EC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image', 'image/file_name', 'objects']\n"
     ]
    }
   ],
   "source": [
    "for example in ds_test.take(3):  # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
    "    print(list(example.keys()))\n",
    "    image = example[\"image\"]\n",
    "    objects = example[\"objects\"]\n",
    "  \n",
    "#     print(objects['location'])\n",
    "    show_inference(detection_model, image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D4g2fSSqwHx-"
   },
   "outputs": [],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation Steps\n",
    "\n",
    "\n",
    "from object_detection import eval_util\n",
    "from object_detection.core import standard_fields as fields\n",
    "from object_detection.metrics import coco_evaluation\n",
    "from object_detection.protos import eval_pb2\n",
    "from object_detection.utils import test_case\n",
    "from object_detection.utils import tf_version\n",
    "\n",
    "def test_get_eval_metric_ops_for_coco_detections(eval_dict, batch_size=1,\n",
    "                                               max_gt_boxes=None,\n",
    "                                               scale_to_absolute=False):\n",
    "    eval_config = eval_pb2.EvalConfig()\n",
    "    eval_config.metrics_set.extend(['pascal_voc_detection_metrics'])\n",
    "    categories = list(category_index.values())\n",
    "\n",
    "    metric_ops = eval_util.get_eval_metric_ops_for_evaluators(\n",
    "        eval_config, categories, eval_dict)\n",
    "    _, update_op = metric_ops['DetectionBoxes_Precision/mAP']\n",
    "\n",
    "    with self.test_session() as sess:\n",
    "        metrics = {}\n",
    "        for key, (value_op, _) in six.iteritems(metric_ops):\n",
    "            metrics[key] = value_op\n",
    "        sess.run(update_op)\n",
    "        metrics = sess.run(metrics)\n",
    "        print(metrics)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Complete Evaluation steps\n",
    "\n",
    "input_data_fields = fields.InputDataFields\n",
    "detection_fields = fields.DetectionResultFields\n",
    "\n",
    "for example in ds_test.take(1):  # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
    "    print(list(example.keys()))\n",
    "    image = example[\"image\"]\n",
    "    objects = example[\"objects\"]\n",
    "  \n",
    "#     print( objects)\n",
    "    print(objects['location'])\n",
    "#     show_inference(detection_model, image)\n",
    "    image_np = np.array(image)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(detection_model, image_np)\n",
    "    \n",
    "#       return eval_util.result_dict_for_single_example(\n",
    "#           image, key, detections, groundtruth,\n",
    "#           scale_to_absolute=scale_to_absolute)\n",
    "\n",
    "\n",
    "#     batch_size = 100\n",
    "#     key = tf.constant([str(i) for i in range(batch_size)])\n",
    "\n",
    "    key = tf.constant('image1')\n",
    "    \n",
    "    groundtruth_boxes = objects['bbox']\n",
    "    groundtruth_classes = objects['type']\n",
    "    groundtruth = {\n",
    "        input_data_fields.groundtruth_boxes: groundtruth_boxes,\n",
    "        input_data_fields.groundtruth_classes: groundtruth_classes,\n",
    "      \n",
    "    }\n",
    "    \n",
    "#     num_detections = tf.convert_to_tensor([len(output_dict['detection_classes'])])\n",
    "    batch_size = 375\n",
    "    num_detection = tf.ones([batch_size])\n",
    "    detections = {\n",
    "        detection_fields.detection_boxes:  output_dict['detection_boxes'],\n",
    "        detection_fields.detection_scores: output_dict['detection_scores'],\n",
    "        detection_fields.detection_classes: output_dict['detection_classes'],\n",
    "        detection_fields.num_detections: num_detections\n",
    "       \n",
    "    }\n",
    "    result_dict = eval_util.result_dict_for_single_example(image, key,detections, groundtruth)\n",
    "#     test_get_eval_metric_ops_for_coco_detections(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -sh test.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import proglog\n",
    "proglog.notebook()\n",
    "\n",
    "write_output = 'output1.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first n seconds\n",
    "# clip1 = VideoFileClip(\"test.mp4\").subclip(0,1)\n",
    "\n",
    "# clip1 = VideoFileClip(\"test.mp4\")\n",
    "\n",
    "clip1 = VideoFileClip(\"accident_compilation.mp4\")\n",
    "\n",
    "\n",
    "white_clip = clip1.fl_image(process_image) \n",
    "\n",
    "white_clip.write_videofile(write_output, audio=False, verbose=False)\n",
    "clip1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "kernel4b7879e069 (3).ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-1.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
